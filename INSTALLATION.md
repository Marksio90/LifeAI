# ğŸš€ LifeAI - Kompletny Przewodnik Instalacji i Testowania

> **NajnowoczeÅ›niejsza platforma AI z zaawansowanymi funkcjami enterprise**

## ğŸ“‹ Spis TreÅ›ci

1. [Wymagania WstÄ™pne](#-wymagania-wstÄ™pne)
2. [Szybki Start (5 minut)](#-szybki-start)
3. [SzczegÃ³Å‚owa Instalacja](#-szczegÃ³Å‚owa-instalacja)
4. [Testowanie Wszystkich Funkcji](#-testowanie-wszystkich-funkcji)
5. [WdroÅ¼enie Produkcyjne](#-wdroÅ¼enie-produkcyjne)
6. [RozwiÄ…zywanie ProblemÃ³w](#-rozwiÄ…zywanie-problemÃ³w)
7. [Zaawansowane Funkcje](#-zaawansowane-funkcje)

---

## ğŸ“¦ Wymagania WstÄ™pne

### Minimalne Wymagania

| Komponent | Wersja Minimalna | Zalecana |
|-----------|------------------|----------|
| **Docker** | 20.10+ | 24.0+ |
| **Docker Compose** | 2.0+ | 2.20+ |
| **Node.js** | 18.0+ | 20.0+ |
| **Python** | 3.10+ | 3.11+ |
| **npm** | 8.0+ | 10.0+ |
| **RAM** | 4GB | 8GB+ |
| **Dysk** | 10GB | 20GB+ |

### Instalacja NarzÄ™dzi

<details>
<summary><b>ğŸ§ Linux (Ubuntu/Debian)</b></summary>

```bash
# Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER

# Docker Compose
sudo apt-get update
sudo apt-get install docker-compose-plugin

# Node.js (via nvm)
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash
nvm install 20
nvm use 20

# Python
sudo apt-get install python3.11 python3-pip
```

</details>

<details>
<summary><b>ğŸ macOS</b></summary>

```bash
# Homebrew (jeÅ›li nie masz)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Docker Desktop
brew install --cask docker

# Node.js
brew install node@20

# Python
brew install python@3.11
```

</details>

<details>
<summary><b>ğŸªŸ Windows (WSL2)</b></summary>

```powershell
# Zainstaluj WSL2
wsl --install

# W WSL2 terminal:
# PostÄ™puj zgodnie z instrukcjami Linux
```

</details>

### Wymagane Klucze API

| Serwis | Opis | Link |
|--------|------|------|
| **OpenAI API** | âš ï¸ **WYMAGANE** - AI, TTS, DALL-E | [platform.openai.com](https://platform.openai.com/api-keys) |
| **Pinecone** | Opcjonalne - Vector DB (produkcja) | [pinecone.io](https://www.pinecone.io/) |

---

## âš¡ Szybki Start

### 1. Sklonuj Repozytorium

```bash
git clone https://github.com/yourusername/LifeAI.git
cd LifeAI
```

### 2. Uruchom AutomatycznÄ… InstalacjÄ™

```bash
# Nadaj uprawnienia
chmod +x setup.sh test.sh

# Uruchom instalacjÄ™
./setup.sh
```

**Skrypt automatycznie:**
- âœ… Sprawdzi wymagania
- âœ… Utworzy plik `.env` z bezpiecznymi kluczami
- âœ… Zainstaluje wszystkie zaleÅ¼noÅ›ci
- âœ… Zbuduje kontenery Docker
- âœ… Uruchomi wszystkie serwisy
- âœ… Zainicjalizuje bazÄ™ danych

### 3. Ustaw Klucz OpenAI

Podczas instalacji zostaniesz poproszony o klucz OpenAI, lub ustaw go rÄ™cznie:

```bash
nano .env
# ZmieÅ„: OPENAI_API_KEY=sk-your-key-here
```

### 4. SprawdÅº Status

```bash
docker-compose ps
```

Wszystkie kontenery powinny byÄ‡ `healthy`:
- âœ… `lifeai-backend` (port 8000)
- âœ… `lifeai-frontend` (port 3000)
- âœ… `lifeai-postgres` (port 5432)
- âœ… `lifeai-redis` (port 6379)

### 5. OtwÃ³rz AplikacjÄ™

- **Frontend:** http://localhost:3000
- **API Docs:** http://localhost:8000/docs
- **GraphQL:** http://localhost:8000/graphql

ğŸ‰ **Gotowe! Aplikacja dziaÅ‚a!**

---

## ğŸ”§ SzczegÃ³Å‚owa Instalacja

### Krok 1: Konfiguracja Åšrodowiska

#### RÄ™czna Konfiguracja `.env`

JeÅ›li wolisz rÄ™cznÄ… konfiguracjÄ™:

```bash
cp .env.example .env
```

Edytuj `.env`:

```bash
# =========================
# ğŸ” BEZPIECZEÅƒSTWO (WYMAGANE!)
# =========================

# Wygeneruj silny klucz:
# openssl rand -hex 32
SECRET_KEY=your-generated-secret-key-here

# =========================
# ğŸ¤– OPENAI (WYMAGANE!)
# =========================
OPENAI_API_KEY=sk-your-openai-api-key-here

# =========================
# ğŸ—„ï¸ BAZA DANYCH
# =========================
POSTGRES_USER=lifeai
POSTGRES_PASSWORD=your-strong-password-min-16-chars
POSTGRES_DB=lifeai

# WAÅ»NE: HasÅ‚o musi byÄ‡ takie samo w obu miejscach!
DATABASE_URL=postgresql://lifeai:your-strong-password-min-16-chars@postgres:5432/lifeai

# =========================
# ğŸ“¦ REDIS
# =========================
REDIS_URL=redis://redis:6379/0

# =========================
# ğŸŒ ÅšRODOWISKO
# =========================
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=INFO

# =========================
# ğŸ”— CORS
# =========================
ALLOWED_ORIGINS=http://localhost:3000,http://frontend:3000
NEXT_PUBLIC_API_URL=http://localhost:8000

# =========================
# ğŸ§  VECTOR DATABASE
# =========================
# Opcje: in-memory (dev) lub pinecone (prod)
VECTOR_DB_TYPE=in-memory

# Dla Pinecone (opcjonalne):
# PINECONE_API_KEY=your-key
# PINECONE_ENVIRONMENT=your-env
# PINECONE_INDEX_NAME=lifeai-memory
```

### Krok 2: Budowa i Uruchomienie

#### Budowa KontenerÃ³w

```bash
# Zbuduj wszystkie obrazy
docker-compose build

# Lub z wymuszonym rebuildem
docker-compose build --no-cache
```

#### Uruchomienie SerwisÃ³w

```bash
# Uruchom w tle
docker-compose up -d

# Lub z logami na Å¼ywo
docker-compose up

# SprawdÅº logi konkretnego serwisu
docker-compose logs -f backend
docker-compose logs -f frontend
```

### Krok 3: Inicjalizacja Bazy Danych

```bash
# Migracje Alembic (jeÅ›li skonfigurowane)
docker-compose exec backend alembic upgrade head

# SprawdÅº status migracji
docker-compose exec backend alembic current

# UtwÃ³rz nowÄ… migracjÄ™ (development)
docker-compose exec backend alembic revision --autogenerate -m "Description"
```

### Krok 4: Weryfikacja Instalacji

```bash
# Uruchom peÅ‚ny test suite
./test.sh

# Lub wybrane testy:
./test.sh --unit          # Tylko testy jednostkowe
./test.sh --integration   # Tylko testy integracyjne
./test.sh --e2e          # Tylko testy E2E
./test.sh --load         # Tylko testy obciÄ…Å¼eniowe
```

---

## ğŸ§ª Testowanie Wszystkich Funkcji

### 1. API Endpoints

#### Health Check

```bash
# Podstawowy health check
curl http://localhost:8000/health/live

# SzczegÃ³Å‚owy health check
curl http://localhost:8000/health/ready | jq .
```

Oczekiwany wynik:
```json
{
  "status": "healthy",
  "checks": {
    "database": true,
    "redis": true,
    "openai": true
  },
  "timestamp": "2025-12-25T10:00:00Z"
}
```

#### REST API

```bash
# Rejestracja uÅ¼ytkownika
curl -X POST http://localhost:8000/api/auth/register \
  -H "Content-Type: application/json" \
  -d '{
    "email": "test@example.com",
    "password": "TestPassword123!",
    "name": "Test User"
  }'

# Login
curl -X POST http://localhost:8000/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "email": "test@example.com",
    "password": "TestPassword123!"
  }'

# Zapisz token z odpowiedzi
TOKEN="your-access-token-here"

# Rozpocznij sesjÄ™ czatu
curl -X POST http://localhost:8000/api/chat/start \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json"

# WyÅ›lij wiadomoÅ›Ä‡
curl -X POST http://localhost:8000/api/chat/message \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "session_id": "session-id-from-previous-response",
    "message": "Jak mogÄ™ poprawiÄ‡ swoje zdrowie?",
    "modality": "text"
  }'
```

### 2. GraphQL API

OtwÃ³rz GraphQL Playground: http://localhost:8000/graphql

**PrzykÅ‚adowe query:**

```graphql
# Pobierz rozmowy
query GetConversations {
  conversations(limit: 10) {
    id
    agentType
    startTime
    messageCount
    lastMessage {
      role
      content
      timestamp
    }
  }
}

# Pobierz analitykÄ™
query GetAnalytics {
  analytics {
    totalConversations
    totalMessages
    averageRating
    agentDistribution {
      agentType
      count
      percentage
    }
  }
}
```

**PrzykÅ‚adowa mutacja:**

```graphql
mutation SendMessage($input: MessageInput!) {
  sendMessage(input: $input) {
    id
    content
    timestamp
    agentType
  }
}
```

**Variables:**
```json
{
  "input": {
    "conversationId": "conv-123",
    "content": "PomÃ³Å¼ mi zaplanowaÄ‡ budÅ¼et",
    "agentType": "FINANCE"
  }
}
```

### 3. WebSocket (Real-time Streaming)

**Testowanie z `wscat`:**

```bash
# Zainstaluj wscat
npm install -g wscat

# PoÅ‚Ä…cz siÄ™ z WebSocket
wscat -c ws://localhost:8000/ws?token=your-jwt-token

# WyÅ›lij wiadomoÅ›Ä‡ (w sesji wscat)
{"type": "message", "content": "Witaj!", "agent_type": "general"}

# Otrzymasz streaming response token po tokenie!
```

**Testowanie z JavaScript:**

```javascript
const ws = new WebSocket('ws://localhost:8000/ws?token=YOUR_TOKEN');

ws.onopen = () => {
  console.log('Connected!');
  ws.send(JSON.stringify({
    type: 'message',
    content: 'Test message',
    agent_type: 'health'
  }));
};

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log('Received:', data);
};
```

### 4. Semantic Caching

**Testowanie cache hit rate:**

```bash
# Pierwsze zapytanie (cache MISS)
curl -X POST http://localhost:8000/api/chat/message \
  -H "Authorization: Bearer $TOKEN" \
  -d '{"session_id": "test", "message": "Jak zaoszczÄ™dziÄ‡ pieniÄ…dze?"}'

# Podobne zapytanie (cache HIT - 70-90% szybsze!)
curl -X POST http://localhost:8000/api/chat/message \
  -H "Authorization: Bearer $TOKEN" \
  -d '{"session_id": "test", "message": "Jak oszczÄ™dzaÄ‡ finanse?"}'

# SprawdÅº metryki cache
curl http://localhost:8000/metrics | grep cache_hit_rate
```

### 5. Rate Limiting

**Testowanie limitÃ³w:**

```bash
# SprawdÅº nagÅ‚Ã³wki rate limit
curl -I http://localhost:8000/api/chat/message \
  -H "Authorization: Bearer $TOKEN"

# NagÅ‚Ã³wki:
# X-RateLimit-Limit: 100
# X-RateLimit-Remaining: 99
# X-RateLimit-Reset: 1640000000

# Test przekroczenia limitu (wyÅ›lij 101 requestÃ³w szybko)
for i in {1..105}; do
  curl -X GET http://localhost:8000/api/analytics/dashboard \
    -H "Authorization: Bearer $TOKEN"
done

# Oczekiwany status po przekroczeniu: 429 Too Many Requests
```

### 6. Text-to-Speech (TTS)

```bash
# Generuj mowÄ™ z tekstu
curl -X POST http://localhost:8000/api/multimodal/tts \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Witaj w LifeAI! Jak mogÄ™ Ci pomÃ³c?",
    "voice": "nova",
    "model": "tts-1-hd"
  }' \
  --output speech.mp3

# OdtwÃ³rz audio
mpv speech.mp3  # lub vlc, ffplay, itp.
```

**DostÄ™pne gÅ‚osy:**
- `alloy` - Neutralny i zbalansowany
- `echo` - MÄ™ski, czysty
- `fable` - Brytyjski akcent
- `onyx` - GÅ‚Ä™boki mÄ™ski
- `nova` - Å»eÅ„ski, energetyczny â­
- `shimmer` - Å»eÅ„ski, miÄ™kki

### 7. DALL-E Image Generation

```bash
# Generuj obraz
curl -X POST http://localhost:8000/api/multimodal/image \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "A serene meditation space with plants and natural light",
    "size": "1024x1024",
    "quality": "hd",
    "style": "natural"
  }' | jq .

# Otrzymasz URL do wygenerowanego obrazu
```

### 8. A/B Testing

```bash
# SprawdÅº przypisanÄ… wersjÄ™ dla uÅ¼ytkownika
curl -X GET "http://localhost:8000/api/ab-test/variant?experiment=ai_response_style&user_id=user123" \
  -H "Authorization: Bearer $TOKEN"

# OdpowiedÅº:
# {"variant": "casual", "config": {"style": "casual", "temperature": 0.9}}

# Zapisz event dla eksperymentu
curl -X POST http://localhost:8000/api/ab-test/event \
  -H "Authorization: Bearer $TOKEN" \
  -d '{
    "experiment": "ai_response_style",
    "user_id": "user123",
    "variant": "casual",
    "event_type": "conversion",
    "value": 5
  }'
```

### 9. Internationalization (i18n)

```bash
# Frontend automatycznie wykrywa jÄ™zyk z przeglÄ…darki

# RÄ™czna zmiana jÄ™zyka:
# 1. OtwÃ³rz http://localhost:3000
# 2. PrzejdÅº do Settings
# 3. Wybierz: Polski lub English

# DostÄ™pne jÄ™zyki:
# - en (English)
# - pl (Polski)
```

### 10. PWA (Progressive Web App)

**Testowanie offline mode:**

1. OtwÃ³rz http://localhost:3000 w Chrome
2. OtwÃ³rz DevTools (F12)
3. PrzejdÅº do Application > Service Workers
4. Zaznacz "Offline"
5. OdÅ›wieÅ¼ stronÄ™
6. âœ… Aplikacja dziaÅ‚a offline!

**Instalacja jako aplikacja:**

1. Kliknij ikonÄ™ "Zainstaluj" w pasku adresu
2. Aplikacja otworzy siÄ™ jako standalone app
3. DziaÅ‚a jak natywna aplikacja!

### 11. Long-Term Memory

```bash
# WysyÅ‚aj wiadomoÅ›ci, aby system uczyÅ‚ siÄ™ preferencji
curl -X POST http://localhost:8000/api/chat/message \
  -H "Authorization: Bearer $TOKEN" \
  -d '{
    "session_id": "test",
    "message": "Jestem wegetarianinem i Ä‡wiczÄ™ 3 razy w tygodniu"
  }'

# System automatycznie zapisze te fakty w pamiÄ™ci dÅ‚ugoterminowej

# SprawdÅº zapisane wspomnienia
curl -X GET http://localhost:8000/api/memory/retrieve \
  -H "Authorization: Bearer $TOKEN" \
  -d '{
    "query": "dieta",
    "user_id": "your-user-id"
  }'

# OdpowiedÅº zawiera relewanatne wspomnienia:
# [
#   {
#     "type": "preference",
#     "content": "User is vegetarian",
#     "importance": 9,
#     "timestamp": "..."
#   }
# ]
```

### 12. Load Testing (k6)

```bash
# Zainstaluj k6
brew install k6  # macOS
# lub
sudo apt install k6  # Linux

# Uruchom test obciÄ…Å¼eniowy
k6 run tests/load/chat-api-load-test.js

# Test symuluje:
# - 50 â†’ 100 â†’ 200 uÅ¼ytkownikÃ³w
# - Rzeczywiste scenariusze uÅ¼ytkowania
# - Chat, analitykÄ™, health checks

# Metryki:
# âœ“ http_req_duration........: avg=250ms p(95)=450ms
# âœ“ http_req_failed..........: 0.12%
# âœ“ chat_response_time.......: avg=1.2s p(95)=1.8s
```

---

## ğŸš€ WdroÅ¼enie Produkcyjne

### Kubernetes + Helm

#### 1. Przygotowanie

```bash
# Zainstaluj Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# Dodaj secrets
kubectl create secret generic lifeai-secrets \
  --from-literal=secret-key=$(openssl rand -hex 32) \
  --from-literal=openai-api-key=sk-your-key \
  --from-literal=postgres-password=$(openssl rand -base64 24)
```

#### 2. Instalacja

```bash
# Instaluj z Helm
helm install lifeai ./helm/lifeai \
  --namespace lifeai \
  --create-namespace \
  --values helm/lifeai/values.yaml

# SprawdÅº status
helm status lifeai -n lifeai

# SprawdÅº pods
kubectl get pods -n lifeai
```

#### 3. Aktualizacja

```bash
# Aktualizuj deployment
helm upgrade lifeai ./helm/lifeai \
  --namespace lifeai \
  --values helm/lifeai/values-prod.yaml

# Rollback (jeÅ›li potrzeba)
helm rollback lifeai -n lifeai
```

#### 4. Skalowanie

```bash
# RÄ™czne skalowanie
kubectl scale deployment lifeai-backend --replicas=5 -n lifeai

# Auto-scaling (HPA juÅ¼ skonfigurowane w values.yaml)
kubectl get hpa -n lifeai

# Skaluje automatycznie 3-10 replik przy 70% CPU
```

#### 5. Monitoring

```bash
# Port-forward Grafana
kubectl port-forward svc/grafana 3001:80 -n lifeai

# OtwÃ³rz: http://localhost:3001
# Login: admin / (sprawdÅº secret)

# Dashboardy:
# - LifeAI Overview
# - API Performance
# - Database Metrics
# - Redis Cache Stats
```

### CI/CD Pipeline

**GitHub Actions juÅ¼ skonfigurowane!**

Pipeline automatycznie:
1. âœ… Uruchamia testy (unit + integration)
2. âœ… Skanuje bezpieczeÅ„stwo (Trivy + Snyk)
3. âœ… Buduje obrazy Docker
4. âœ… Pushuje do registry
5. âœ… Deployuje na Kubernetes
6. âœ… Uruchamia E2E testy
7. âœ… Uruchamia testy obciÄ…Å¼eniowe
8. âœ… Rollback przy bÅ‚Ä™dzie

**Workflow:** `.github/workflows/ci-cd.yaml`

```bash
# Push uruchamia pipeline
git push origin main

# SprawdÅº status
# GitHub > Actions > Latest workflow run
```

### Zmienne Åšrodowiskowe (Produkcja)

```bash
# Produkcyjny .env
ENVIRONMENT=production
DEBUG=false
LOG_LEVEL=WARNING

# UÅ¼yj zewnÄ™trznych serwisÃ³w
DATABASE_URL=postgresql://user:pass@prod-db.example.com:5432/lifeai
REDIS_URL=redis://prod-redis.example.com:6379/0

# Vector DB - Pinecone dla produkcji
VECTOR_DB_TYPE=pinecone
PINECONE_API_KEY=your-prod-key
PINECONE_ENVIRONMENT=us-west1-gcp
PINECONE_INDEX_NAME=lifeai-prod

# ZwiÄ™ksz limity
DB_POOL_SIZE=50
DB_MAX_OVERFLOW=100
```

---

## ğŸ› RozwiÄ…zywanie ProblemÃ³w

### Problem: Backend nie startuje

```bash
# SprawdÅº logi
docker-compose logs backend

# Typowe przyczyny:
# 1. Brak klucza OpenAI
grep OPENAI_API_KEY .env

# 2. BÅ‚Ä…d poÅ‚Ä…czenia z bazÄ…
docker-compose exec backend python -c "from app.db.session import engine; engine.connect()"

# 3. Port zajÄ™ty
lsof -i :8000
# Zabij proces lub zmieÅ„ port w docker-compose.yml
```

### Problem: Frontend nie Å‚Ä…czy siÄ™ z backendem

```bash
# SprawdÅº CORS
curl -H "Origin: http://localhost:3000" \
     -H "Access-Control-Request-Method: POST" \
     -I http://localhost:8000/api/chat/start

# Dodaj origin do .env
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001

# Restart backend
docker-compose restart backend
```

### Problem: PostgreSQL Out of Memory

```bash
# ZwiÄ™ksz shared_buffers w docker-compose.yml
services:
  postgres:
    command: postgres -c shared_buffers=256MB -c max_connections=200

# Restart
docker-compose restart postgres
```

### Problem: Redis Connection Errors

```bash
# SprawdÅº status
docker-compose exec redis redis-cli ping

# WyczyÅ›Ä‡ cache
docker-compose exec redis redis-cli FLUSHALL

# SprawdÅº memory
docker-compose exec redis redis-cli INFO memory
```

### Problem: Wolne API Responses

```bash
# 1. SprawdÅº cache hit rate
curl http://localhost:8000/metrics | grep cache

# 2. Enable query logging (development only!)
# W docker-compose.yml dla postgres:
command: postgres -c log_statement=all

# 3. SprawdÅº slow queries
docker-compose exec postgres psql -U lifeai -c \
  "SELECT query, mean_exec_time FROM pg_stat_statements ORDER BY mean_exec_time DESC LIMIT 10;"

# 4. ZwiÄ™ksz connection pool
# W .env:
DB_POOL_SIZE=30
DB_MAX_OVERFLOW=60
```

### Problem: OpenAI Rate Limits

```bash
# WÅ‚Ä…cz semantic caching (redukcja 70-90%!)
# JuÅ¼ wÅ‚Ä…czone domyÅ›lnie w backend/app/cache/semantic_cache.py

# SprawdÅº usage
curl https://api.openai.com/v1/usage \
  -H "Authorization: Bearer $OPENAI_API_KEY"

# RozwaÅ¼ upgrade planu: https://platform.openai.com/account/billing
```

### Problem: WebSocket Disconnects

```bash
# ZwiÄ™ksz timeouty w nginx/ingress
# nginx.conf:
proxy_read_timeout 3600s;
proxy_send_timeout 3600s;

# Kubernetes Ingress:
annotations:
  nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
  nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"
```

### Czyszczenie i Reset

```bash
# Zatrzymaj wszystko
docker-compose down

# UsuÅ„ wszystkie dane (OSTROÅ»NIE!)
docker-compose down -v

# PeÅ‚ny rebuild
docker-compose build --no-cache
docker-compose up -d

# Reset bazy danych
docker-compose exec postgres psql -U lifeai -c "DROP DATABASE lifeai; CREATE DATABASE lifeai;"
docker-compose exec backend alembic upgrade head
```

---

## ğŸ¯ Zaawansowane Funkcje

### 1. Custom Agent Creation

```python
# backend/app/agents/custom_agent.py

from app.agents.base import BaseAgent
from app.core.agent_types import AgentRole

class CustomAgent(BaseAgent):
    def __init__(self):
        super().__init__(
            role=AgentRole.CUSTOM,
            system_prompt="You are a custom specialized agent..."
        )

    async def process_message(self, message: str, context: dict):
        # Custom logic
        response = await self.generate_response(message, context)
        return response

# Zarejestruj w app/agents/__init__.py
```

### 2. Custom Prompt Templates

```python
# backend/app/ai/prompt_templates.py

# Dodaj nowy template
CUSTOM_TEMPLATE = """
You are {role_name}.
User preferences: {preferences}
Recent context: {context}
Current time: {current_time}

Respond to: {user_message}
"""

# UÅ¼yj w agencie
template_engine.register_template("custom", CUSTOM_TEMPLATE)
```

### 3. Webhook Integration

```python
# backend/app/webhooks/handlers.py

from fastapi import APIRouter, Request

router = APIRouter()

@router.post("/webhook/conversation-end")
async def on_conversation_end(request: Request):
    data = await request.json()

    # WyÅ›lij do zewnÄ™trznego systemu
    await send_to_crm(data)
    await send_to_analytics(data)

    return {"status": "processed"}

# Zarejestruj w main.py
```

### 4. Custom Vector Store

```python
# backend/app/vector_store/custom_store.py

from app.vector_store.base import BaseVectorStore

class CustomVectorStore(BaseVectorStore):
    async def store_embedding(self, vector, metadata):
        # Implementacja dla Weaviate, Qdrant, etc.
        pass

    async def search_similar(self, query_vector, top_k=5):
        # Similarity search
        pass

# Konfiguruj w .env
VECTOR_DB_TYPE=custom
```

### 5. Multi-Tenant Support

```python
# backend/app/middleware/tenant.py

from starlette.middleware.base import BaseHTTPMiddleware

class TenantMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request, call_next):
        # WyciÄ…gnij tenant ID z nagÅ‚Ã³wka lub subdomeny
        tenant_id = request.headers.get("X-Tenant-ID")

        # Ustaw w context
        request.state.tenant_id = tenant_id

        response = await call_next(request)
        return response

# Dodaj w main.py
app.add_middleware(TenantMiddleware)
```

---

## ğŸ“Š Monitoring i Metryki

### Prometheus Metrics

```bash
# Endpoint z metrykami
curl http://localhost:8000/metrics

# Kluczowe metryki:
# - http_requests_total
# - http_request_duration_seconds
# - cache_hit_rate
# - openai_api_calls_total
# - active_websocket_connections
# - database_connection_pool_size
```

### Grafana Dashboards

**DomyÅ›lne dashboardy:**
1. API Overview
2. Database Performance
3. Cache Analytics
4. AI/ML Metrics
5. User Activity

**Import custom dashboard:**

```bash
# Skopiuj JSON do Grafana UI
# Dashboard ID: 1860 (Node Exporter)
# Dashboard ID: 3662 (Prometheus)
```

### Logging

```bash
# Structured JSON logs
docker-compose logs backend | jq .

# Filter by level
docker-compose logs backend | jq 'select(.level=="ERROR")'

# Filter by request_id
docker-compose logs backend | jq 'select(.request_id=="req-123")'

# Realtime monitoring
docker-compose logs -f backend | jq -r '.timestamp + " " + .level + " " + .message'
```

---

## ğŸ” BezpieczeÅ„stwo

### Security Checklist

- [ ] âœ… SECRET_KEY jest losowy (min 32 bajty)
- [ ] âœ… HasÅ‚a do bazy danych sÄ… silne (min 16 znakÃ³w)
- [ ] âœ… .env NIE jest w git (w .gitignore)
- [ ] âœ… HTTPS w produkcji
- [ ] âœ… Rate limiting wÅ‚Ä…czony
- [ ] âœ… CORS poprawnie skonfigurowany
- [ ] âœ… SQL Injection protection (SQLAlchemy ORM)
- [ ] âœ… XSS protection (React auto-escaping)
- [ ] âœ… CSRF protection dla formularzy
- [ ] âœ… JWT token expiration (24h)
- [ ] âœ… Dependency scanning (npm audit, safety)

### Regularne Audyty

```bash
# Python dependencies
pip3 install safety
safety check

# npm dependencies
npm audit

# Docker images
docker scan lifeai-backend:latest

# Secrets scanning
pip3 install gitleaks
gitleaks detect --source . --verbose
```

---

## ğŸ“š Dodatkowe Zasoby

### Dokumentacja

- **API Documentation:** http://localhost:8000/docs (Swagger)
- **GraphQL Playground:** http://localhost:8000/graphql
- **Code Documentation:** Wygeneruj z `pydoc` / `jsdoc`

### NarzÄ™dzia Deweloperskie

```bash
# Backend REPL
docker-compose exec backend python

# Database console
docker-compose exec postgres psql -U lifeai

# Redis console
docker-compose exec redis redis-cli

# Frontend hot reload juÅ¼ wÅ‚Ä…czony
```

### Przydatne Komendy

```bash
# Szybki restart po zmianach
docker-compose restart backend frontend

# Rebuild tylko jednego serwisu
docker-compose build backend
docker-compose up -d backend

# SprawdÅº zuÅ¼ycie zasobÃ³w
docker stats

# Backup bazy danych
docker-compose exec postgres pg_dump -U lifeai lifeai > backup.sql

# Restore bazy danych
docker-compose exec -T postgres psql -U lifeai lifeai < backup.sql
```

---

## ğŸ“ Szkolenia i PrzykÅ‚ady

### PrzykÅ‚adowe Scenariusze

<details>
<summary><b>Scenariusz 1: Health Coach Conversation</b></summary>

```bash
# Rozpocznij sesjÄ™
curl -X POST http://localhost:8000/api/chat/start \
  -H "Authorization: Bearer $TOKEN" \
  -d '{"agent_type": "health"}'

# WiadomoÅ›ci:
# 1. "ChcÄ™ schudnÄ…Ä‡ 5kg w 2 miesiÄ…ce"
# 2. "Jakie Ä‡wiczenia polecasz?"
# 3. "Jak powinienem siÄ™ odÅ¼ywiaÄ‡?"

# System:
# - ZapamiÄ™tuje cel (5kg w 2 miesiÄ…ce)
# - Personalizuje rekomendacje
# - Generuje plan treningowy
```

</details>

<details>
<summary><b>Scenariusz 2: Financial Planning</b></summary>

```bash
# Agent finansowy
curl -X POST http://localhost:8000/api/chat/start \
  -H "Authorization: Bearer $TOKEN" \
  -d '{"agent_type": "finance"}'

# WiadomoÅ›ci:
# 1. "Mam 5000 zÅ‚ miesiÄ™cznie, jak zaplanowaÄ‡ budÅ¼et?"
# 2. "ChcÄ™ zaoszczÄ™dziÄ‡ na mieszkanie"

# System:
# - Analizuje przychody
# - Tworzy budÅ¼et 50/30/20
# - Sugeruje strategie oszczÄ™dnoÅ›ci
# - Wizualizuje w dashboard (wykresy!)
```

</details>

---

## ğŸ¤ Wsparcie

### ZgÅ‚aszanie ProblemÃ³w

1. SprawdÅº [FAQ](#-rozwiÄ…zywanie-problemÃ³w)
2. Przeszukaj [GitHub Issues](https://github.com/yourusername/LifeAI/issues)
3. UtwÃ³rz nowy issue z:
   - Opisem problemu
   - Krokami do reprodukcji
   - Logami (`docker-compose logs`)
   - Informacjami o Å›rodowisku

### Community

- **Discord:** [Join Server](https://discord.gg/lifeai)
- **Forum:** [discuss.lifeai.com](https://discuss.lifeai.com)
- **Email:** support@lifeai.com

---

## ğŸ“„ Licencja

MIT License - patrz [LICENSE](LICENSE)

---

**ğŸ‰ Gratulacje! Masz teraz w peÅ‚ni funkcjonalnÄ…, zaawansowanÄ… platformÄ™ AI! ğŸ‰**

Made with â¤ï¸ by LifeAI Team
